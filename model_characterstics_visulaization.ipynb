{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/scratch/abhimanyu/work/miniconda3/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.utils\n",
    "import enum\n",
    "import csv\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "def get_sparse_weights(weight,N=2,M=4, get_mask = False):\n",
    "    length = weight.numel()\n",
    "    \n",
    "    group = int(length/M)\n",
    "\n",
    "    weight_temp = weight.detach().abs().reshape(group, M)\n",
    "    index = torch.argsort(weight_temp, dim=1)[:, :int(M-N)]\n",
    "\n",
    "    w_b = torch.ones(weight_temp.shape, device=weight_temp.device)\n",
    "    w_b = w_b.scatter_(dim=1, index=index, value=0).reshape(weight.shape)\n",
    "\n",
    "    mask = w_b\n",
    "\n",
    "    if get_mask:\n",
    "        return w_b*weight, mask\n",
    "    \n",
    "    return w_b*weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/scratch/abhimanyu/work/google_nm_sparse_training/pytorch-image-models-sparsity/vit_model_full_1105/SRSTE_NM_1_128/model_stats.csv\n"
     ]
    }
   ],
   "source": [
    "folder = '/usr/scratch/abhimanyu/work/google_nm_sparse_training/pytorch-image-models-sparsity/vit_model_full_1105/SRSTE_NM_1_128/'\n",
    "\n",
    "all_files = []\n",
    "for file in os.listdir(folder):\n",
    "    if file.endswith(\".pt\"):\n",
    "        # print path name of selected files\n",
    "        all_files.append(file)\n",
    "\n",
    "\n",
    "stat_file = os.path.join(folder, 'model_stats.csv')\n",
    "# state = torch.load(file_name)\n",
    "print(stat_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(state['module.blocks.0.mlp.fc1.weight_grad'])\n",
    "# print(state)\n",
    "prev_weights_array = OrderedDict()\n",
    "prev_grad_array = OrderedDict()\n",
    "\n",
    "os.remove(stat_file)\n",
    "for file_name in all_files:\n",
    "\n",
    "    state = torch.load(os.path.join(folder, file_name))\n",
    "    curr_weights_array = OrderedDict()\n",
    "    curr_grad_array = OrderedDict()\n",
    "    # print(state)\n",
    "    for name in state:\n",
    "        # print(name)\n",
    "        if name == 'loss':\n",
    "            current_loss = state['loss'].item()\n",
    "            # rowd.update({f'loss' : })\n",
    "        elif 'grad' in name:\n",
    "            ## Gradients of the weights\n",
    "            curr_grad_array.update({name:state[name].detach().clone()})\n",
    "        elif 'weight' in name:\n",
    "            curr_weights_array.update({name:state[name].detach().clone()})\n",
    "\n",
    "\n",
    "    if(len(prev_weights_array) != 0 and len(prev_grad_array) != 0 ):\n",
    "        rowd = OrderedDict(loss=current_loss)\n",
    "        # print(len(curr_weights_array), len(curr_grad_array),len(prev_weights_array),len(prev_grad_array)) \n",
    "        for weight_name,grad_name,weight_last_name,grad_last_name in zip(curr_weights_array,curr_grad_array,prev_weights_array,prev_grad_array):\n",
    "            \n",
    "            name_fc = weight_name.removeprefix('module.').removesuffix('.weight')\n",
    "\n",
    "            grad = curr_grad_array[grad_name] \n",
    "            rowd.update({f'grad_mean_' + str(name_fc) :  torch.mean(grad).cpu().numpy()})  \n",
    "            rowd.update({f'grad_std_' + str(name_fc) :  torch.std(grad).cpu().numpy()})  \n",
    "            rowd.update({f'grad_l2norm_' + str(name_fc) :  torch.norm(grad).cpu().numpy()})  \n",
    "            rowd.update({f'grad_linfnorm_' + str(name_fc) :  torch.max(grad).cpu().numpy()}) \n",
    "\n",
    "            # for name, param in model.named_parameters():\n",
    "            weight = curr_weights_array[weight_name]\n",
    "            curr_weights, curr_sparse_mask = get_sparse_weights(weight, 1, 128,  get_mask=True)\n",
    "            rowd.update({f'sparse_weight_mean_' + str(name_fc) : torch.mean(curr_weights).cpu().numpy()})\n",
    "            rowd.update({f'sparse_weight_std_' + str(name_fc) :  torch.std(curr_weights).cpu().numpy()})\n",
    "\n",
    "            ## W2-W1\n",
    "            weight_last = prev_weights_array[weight_last_name] \n",
    "            prev_weights_fc, prev_sparse_mask = get_sparse_weights(weight_last.detach().clone(), 1, 128, get_mask=True)\n",
    "            weight_diff = curr_weights - prev_weights_fc \n",
    "            # print(f'{name} : {weight_diff}')\n",
    "            rowd.update({f'weight_diff_l2_norm_' + str(name_fc) :  torch.norm(weight_diff, p=2).cpu().numpy()}) \n",
    "            rowd.update({f'weight_diff_linf_norm_' + str(name_fc) :  torch.max(weight_diff).cpu().numpy()}) \n",
    "            rowd.update({f'weight_diff_std_norm_' + str(name_fc) :  torch.std(weight_diff).cpu().numpy()}) \n",
    "\n",
    "            ##sparse_mask\n",
    "            mask_diff = curr_sparse_mask - prev_sparse_mask\n",
    "            rowd.update({f'SAD_L1_' + str(name_fc) :  torch.norm(mask_diff, p=1).cpu().numpy()}) \n",
    "            rowd.update({f'SAD_L2_' + str(name_fc) :  torch.norm(mask_diff, p=2).cpu().numpy()})\n",
    "            rowd.update({f'SAD_std_' + str(name_fc) :  torch.std(mask_diff).cpu().numpy()})\n",
    "\n",
    "            ## G2 - G1\n",
    "            grad_last = prev_grad_array[grad_last_name] \n",
    "            grad_diff = grad - grad_last\n",
    "            rowd.update({f'grad_diff_l2_' + str(name_fc) :  torch.norm(grad_diff, p=2).cpu().numpy()}) \n",
    "            rowd.update({f'grad_diff_mean_' + str(name_fc) :  torch.mean(grad_diff).cpu().numpy()}) \n",
    "            rowd.update({f'grad_diff_std_' + str(name_fc) :  torch.std(grad_diff).cpu().numpy()})  \n",
    "\n",
    "        ## Write to the file\n",
    "        with open(stat_file, mode='a') as cf:\n",
    "            dw = csv.DictWriter(cf, fieldnames=rowd.keys())\n",
    "            # Get the size of the file\n",
    "            file_size = os.path.getsize(stat_file)\n",
    "        \n",
    "            # Check if the file is empty\n",
    "            if file_size == 0:\n",
    "                dw.writeheader()\n",
    "            dw.writerow(rowd)\n",
    "    prev_weights_array = curr_weights_array \n",
    "    prev_grad_array = curr_grad_array\n",
    "\n",
    "      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
